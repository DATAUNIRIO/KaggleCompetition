{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Cleansing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import xgboost as xgb\n",
    "#from sklearn.preprocessing import LabelEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train = pd.read_csv('train_clean.csv')\n",
    "test = pd.read_csv('test_clean.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define Function for feature importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_feature_importance(model):\n",
    "    Importance = model.get_fscore()\n",
    "    Importance = list(Importance.items())\n",
    "    Feature= []\n",
    "    Score = []\n",
    "    for each in Importance:\n",
    "        Feature.append(each[0])\n",
    "        Score.append(each[1])\n",
    "    df = pd.DataFrame({'Feature':Feature,'Score':Score}).sort_values(by=['Score'],ascending=[0])\n",
    "    return df  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CV Check: With Additional Features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Add Time Related Features**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Add month-year\n",
    "train['timestamp'] = pd.to_datetime(train['timestamp'])\n",
    "month_year = (train.timestamp.dt.month + train.timestamp.dt.year * 100)\n",
    "month_year_cnt_map = month_year.value_counts().to_dict()\n",
    "train['month_year_cnt'] = month_year.map(month_year_cnt_map)\n",
    "test['timestamp'] = pd.to_datetime(test['timestamp'])\n",
    "month_year = (test.timestamp.dt.month + test.timestamp.dt.year * 100)\n",
    "month_year_cnt_map = month_year.value_counts().to_dict()\n",
    "test['month_year_cnt'] = month_year.map(month_year_cnt_map)\n",
    "# Add week-year count\n",
    "week_year = (train.timestamp.dt.weekofyear + train.timestamp.dt.year * 100)\n",
    "week_year_cnt_map = week_year.value_counts().to_dict()\n",
    "train['week_year_cnt'] = week_year.map(week_year_cnt_map)\n",
    "week_year = (test.timestamp.dt.weekofyear + test.timestamp.dt.year * 100)\n",
    "week_year_cnt_map = week_year.value_counts().to_dict()\n",
    "test['week_year_cnt'] = week_year.map(week_year_cnt_map)\n",
    "# Add month and day-of-week\n",
    "train['month'] = train.timestamp.dt.month\n",
    "train['dow'] = train.timestamp.dt.dayofweek\n",
    "test['month'] = test.timestamp.dt.month\n",
    "test['dow'] = test.timestamp.dt.dayofweek\n",
    "# Other feature engineering\n",
    "train['rel_floor'] = train['floor'] / train['max_floor'].astype(float)\n",
    "train['rel_floor_rev'] = (train['max_floor'] - train['floor']) / train['max_floor'].astype(float)\n",
    "train['rel_kitch_sq'] = train['kitch_sq'] / train['full_sq'].astype(float)\n",
    "test['rel_floor'] = test['floor'] / test['max_floor'].astype(float)\n",
    "test['rel_floor_rev'] = (test['max_floor'] - test['floor']) / test['max_floor'].astype(float)\n",
    "test['rel_kitch_sq'] = test['kitch_sq'] / test['full_sq'].astype(float)\n",
    "train.apartment_name=train.sub_area.astype(str) + train['metro_km_avto'].astype(str)\n",
    "test.apartment_name=test.sub_area.astype(str) + train['metro_km_avto'].astype(str)\n",
    "train['room_size'] = train['life_sq'] / train['num_room'].astype(float)\n",
    "test['room_size'] = test['life_sq'] / test['num_room'].astype(float)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Add Handmade Features**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_ratio_preschool(df):\n",
    "    df['ratio_preschool'] = df['children_preschool'] / (df['children_school'] + 1)\n",
    "    return df\n",
    "\n",
    "train = get_ratio_preschool(train)\n",
    "test = get_ratio_preschool(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_extra_area(df):\n",
    "    df['extra_area'] = df['full_sq'] - df['life_sq']\n",
    "    return df\n",
    "\n",
    "train = get_extra_area(train)\n",
    "test = get_extra_area(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_floor_ratio(df):\n",
    "    df['floor_ratio'] = df['max_floor'] - df['floor']\n",
    "    return df\n",
    "\n",
    "train = get_floor_ratio(train)\n",
    "test = get_floor_ratio(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_room_avg_size(df):\n",
    "    df['room_avg_size'] = (df['life_sq'] - df['kitch_sq']) / (df['num_room'] + 1)\n",
    "    return df\n",
    "\n",
    "train = get_room_avg_size(train)\n",
    "test = get_room_avg_size(test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Add average house price!!!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## add moscow average price"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def add_moscow_price(df):\n",
    "    moscow_avg_price = pd.read_csv('moscow_avg_price.csv')\n",
    "\n",
    "    moscow_avg_price = moscow_avg_price.rename(columns={'timestamp':'t_timestamp'})\n",
    "    df['date'] = df['timestamp'].apply(lambda x: x.strftime('%Y-%m-%d'))\n",
    "    df = df.merge(moscow_avg_price, left_on='date', right_on='t_timestamp').drop(['date', 't_timestamp'], axis=1)\n",
    "    return df\n",
    "\n",
    "train_avg_price = add_moscow_price(train)\n",
    "test_avg_price = add_moscow_price(test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## add subarea price"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def add_subarea_price(df, is_train):\n",
    "    if is_train:\n",
    "        train_raw = pd.read_csv('train.csv')\n",
    "        train_raw = train_raw.rename(columns={'sub_area':'sub_area_raw'})\n",
    "        df = df.merge(train_raw[['id', 'sub_area_raw']], on='id')\n",
    "    else:\n",
    "        test_raw = pd.read_csv('test.csv')\n",
    "        test_raw = test_raw.rename(columns={'sub_area':'sub_area_raw'})\n",
    "        df = df.merge(test_raw[['id', 'sub_area_raw']], on='id')\n",
    "        \n",
    "    df['date'] = df['timestamp'].apply(lambda x: x.strftime('%Y-%m-%d'))\n",
    "    \n",
    "    subarea_avg_price = pd.read_csv('sub_area_avg_price.csv')\n",
    "    subarea_avg_price = subarea_avg_price.rename(columns={'timestamp':'t_timestamp', 'sub_area':'t_sub_area'})\n",
    "    \n",
    "    df = df.merge(subarea_avg_price, how='left', left_on=['date', 'sub_area_raw'], right_on=['t_timestamp', 't_sub_area'])   \n",
    "    \n",
    "    return df\n",
    "\n",
    "train_avg_price = add_subarea_price(train_avg_price, is_train=True).drop(['date', 't_sub_area', 't_timestamp', 'sub_area_raw'], axis=1)\n",
    "test_avg_price = add_subarea_price(test_avg_price, is_train=False).drop(['date', 't_sub_area', 't_timestamp', 'sub_area_raw'], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Use outside moscow price"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_outside_moscow_price(df):\n",
    "    outside_moscow_avg_price = pd.read_csv('outside_avg_price.csv')\n",
    "\n",
    "    outside_moscow_avg_price = outside_moscow_avg_price.rename(columns={'timestamp':'t_timestamp'})\n",
    "    df['date'] = df['timestamp'].apply(lambda x: x.strftime('%Y-%m-%d'))\n",
    "    df = df.merge(outside_moscow_avg_price, left_on='date', right_on='t_timestamp').drop(['date', 't_timestamp'], axis=1)\n",
    "    \n",
    "    return df\n",
    "\n",
    "train_avg_price = add_outside_moscow_price(train_avg_price)\n",
    "idx = pd.isnull(train_avg_price['sub_area_avg_price_eur'])\n",
    "train_avg_price.loc[idx, 'sub_area_avg_price_eur'] = train_avg_price.loc[idx, 'outside_moscow_eur']\n",
    "train_avg_price.loc[idx, 'sub_area_avg_price_rub'] = train_avg_price.loc[idx, 'outside_moscow_rub']\n",
    "train_avg_price.loc[idx, 'sub_area_avg_price_usd'] = train_avg_price.loc[idx, 'outside_moscow_usd']\n",
    "train_avg_price = train_avg_price.drop(['outside_moscow_eur', 'outside_moscow_rub', 'outside_moscow_usd'], axis=1)\n",
    "\n",
    "test_avg_price = add_outside_moscow_price(test_avg_price)\n",
    "idx = pd.isnull(train_avg_price['sub_area_avg_price_eur'])\n",
    "test_avg_price.loc[idx, 'sub_area_avg_price_eur'] = test_avg_price.loc[idx, 'outside_moscow_eur']\n",
    "test_avg_price.loc[idx, 'sub_area_avg_price_rub'] = test_avg_price.loc[idx, 'outside_moscow_rub']\n",
    "test_avg_price.loc[idx, 'sub_area_avg_price_usd'] = test_avg_price.loc[idx, 'outside_moscow_usd']\n",
    "test_avg_price = test_avg_price.drop(['outside_moscow_eur', 'outside_moscow_rub', 'outside_moscow_usd'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = train_avg_price.drop(['moscow_avg_price_avg_usd', 'moscow_avg_price_high_eur',\n",
    "       'moscow_avg_price_high_rub', 'moscow_avg_price_high_usd',\n",
    "       'moscow_avg_price_low_eur', 'moscow_avg_price_low_rub',\n",
    "       'moscow_avg_price_low_usd', 'sub_area_avg_price_eur','sub_area_avg_price_usd'],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test = test_avg_price.drop(['moscow_avg_price_avg_usd', 'moscow_avg_price_high_eur',\n",
    "       'moscow_avg_price_high_rub', 'moscow_avg_price_high_usd',\n",
    "       'moscow_avg_price_low_eur', 'moscow_avg_price_low_rub',\n",
    "       'moscow_avg_price_low_usd', 'sub_area_avg_price_eur','sub_area_avg_price_usd'],axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create New Labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "fill_fullsq = np.mean(train[train.full_sq.notnull()]['full_sq'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "train['full_sq'] = train['full_sq'].fillna(fill_fullsq)\n",
    "fill_fullsq = np.mean(test[test.full_sq.notnull()]['full_sq'])\n",
    "test['full_sq'] = test['full_sq'].fillna(fill_fullsq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "train['sub_area_avg_price_rub'] = train['sub_area_avg_price_rub']*train['full_sq']\n",
    "test['sub_area_avg_price_rub'] = test['sub_area_avg_price_rub']*test['full_sq']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "gap = train['price_doc'] - train['sub_area_avg_price_rub']\n",
    "train['gap'] = gap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "col = list(test.columns)[2:]\n",
    "col = col.remove('sub_area_avg_price_rub')\n",
    "label = gap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0         5850000\n",
       "1         6000000\n",
       "2         5700000\n",
       "3        13100000\n",
       "4        16331452\n",
       "5         9100000\n",
       "6         5500000\n",
       "7         2000000\n",
       "8         5300000\n",
       "9         4650000\n",
       "10        4800000\n",
       "11        5100000\n",
       "12        5200000\n",
       "13        5000000\n",
       "14        1850000\n",
       "15        6300000\n",
       "16        5900000\n",
       "17        7900000\n",
       "18        5200000\n",
       "19        8200000\n",
       "20        5200000\n",
       "21        6250000\n",
       "22        5750000\n",
       "23        6000000\n",
       "24        1050000\n",
       "25        5000000\n",
       "26        4700000\n",
       "27        8254400\n",
       "28        5900000\n",
       "29        6200000\n",
       "           ...   \n",
       "29232    10000000\n",
       "29233    25039300\n",
       "29234     4350000\n",
       "29235     7567425\n",
       "29236    11438948\n",
       "29237    10139368\n",
       "29238     6125400\n",
       "29239     6373324\n",
       "29240     6888144\n",
       "29241     9227657\n",
       "29242    12610000\n",
       "29243     2394300\n",
       "29244     6800000\n",
       "29245     4066740\n",
       "29246     6300000\n",
       "29247     9014972\n",
       "29248     7800000\n",
       "29249     6370777\n",
       "29250     5778893\n",
       "29251     9500000\n",
       "29252     5000000\n",
       "29253    10544070\n",
       "29254    12000000\n",
       "29255    10262010\n",
       "29256     6750554\n",
       "29257     7400000\n",
       "29258    25000000\n",
       "29259     6970959\n",
       "29260    13500000\n",
       "29261     5600000\n",
       "Name: price_doc, dtype: int64"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.price_doc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "cannot label index with a null key",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-73-fc58f33b4c8b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdtrain\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mxgb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDMatrix\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcol\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'sub_area_avg_price_rub'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/home/jiashen/env3/lib/python3.5/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   2057\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_getitem_multilevel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2058\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2059\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_getitem_column\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2060\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2061\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_getitem_column\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/jiashen/env3/lib/python3.5/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m_getitem_column\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   2064\u001b[0m         \u001b[0;31m# get column\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2065\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_unique\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2066\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_item_cache\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2067\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2068\u001b[0m         \u001b[0;31m# duplicate columns & possible reduce dimensionality\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/jiashen/env3/lib/python3.5/site-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36m_get_item_cache\u001b[0;34m(self, item)\u001b[0m\n\u001b[1;32m   1384\u001b[0m         \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcache\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1385\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mres\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1386\u001b[0;31m             \u001b[0mvalues\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_data\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1387\u001b[0m             \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_box_item_values\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalues\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1388\u001b[0m             \u001b[0mcache\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mres\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/jiashen/env3/lib/python3.5/site-packages/pandas/core/internals.py\u001b[0m in \u001b[0;36mget\u001b[0;34m(self, item, fastpath)\u001b[0m\n\u001b[1;32m   3550\u001b[0m                         \u001b[0mloc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mindexer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3551\u001b[0m                     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3552\u001b[0;31m                         \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"cannot label index with a null key\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3553\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3554\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfastpath\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfastpath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: cannot label index with a null key"
     ]
    }
   ],
   "source": [
    "dtrain = xgb.DMatrix(train[col],train['gap'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\ttrain-rmse:14.427+0.00332693\ttest-rmse:14.427+0.00733507\n",
      "[50]\ttrain-rmse:1.16127+0.001081\ttest-rmse:1.16531+0.00683706\n",
      "[100]\ttrain-rmse:0.317255+0.00347275\ttest-rmse:0.343961+0.00669282\n",
      "[150]\ttrain-rmse:0.289677+0.00319547\ttest-rmse:0.329413+0.00875479\n",
      "[200]\ttrain-rmse:0.277802+0.0029206\ttest-rmse:0.327828+0.0086893\n",
      "[250]\ttrain-rmse:0.268052+0.00344849\ttest-rmse:0.327477+0.0085827\n",
      "[300]\ttrain-rmse:0.25905+0.00340065\ttest-rmse:0.327283+0.0085097\n"
     ]
    }
   ],
   "source": [
    "params = {\n",
    "   'eta': 0.05, ## Try 0.01,3,5\n",
    "   'max_depth': 5,## Try 4,5,6\n",
    "   'subsample': 0.7,\n",
    "   'colsample_bytree': 0.7,\n",
    "   'objective': 'reg:linear',\n",
    "    'eval_metric': 'rmse',\n",
    "    'silent': 1\n",
    "}\n",
    "xgb_cvalid = xgb.cv(params, dtrain, num_boost_round=1000, early_stopping_rounds=20,\n",
    "     verbose_eval=50, show_stdv=True,seed=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('TRAIN:', array([ 5853,  5854,  5855, ..., 29259, 29260, 29261]), 'TEST:', array([   0,    1,    2, ..., 5850, 5851, 5852]))\n",
      "training done\n",
      "RMSLE: 0.380449141148\n",
      "('TRAIN:', array([    0,     1,     2, ..., 29259, 29260, 29261]), 'TEST:', array([ 5853,  5854,  5855, ..., 11703, 11704, 11705]))\n",
      "training done\n",
      "RMSLE: 0.31098244636\n",
      "('TRAIN:', array([    0,     1,     2, ..., 29259, 29260, 29261]), 'TEST:', array([11706, 11707, 11708, ..., 17555, 17556, 17557]))\n",
      "training done\n",
      "RMSLE: 0.329488971397\n",
      "('TRAIN:', array([    0,     1,     2, ..., 29259, 29260, 29261]), 'TEST:', array([17558, 17559, 17560, ..., 23407, 23408, 23409]))\n",
      "training done\n",
      "RMSLE: 0.321559446221\n",
      "('TRAIN:', array([    0,     1,     2, ..., 23407, 23408, 23409]), 'TEST:', array([23410, 23411, 23412, ..., 29259, 29260, 29261]))\n",
      "training done\n",
      "RMSLE: 0.304411301792\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import mean_squared_error as mse\n",
    "\n",
    "kf = KFold(n_splits=5,shuffle=False)\n",
    "col = list(test_avg_price.columns)[2:]\n",
    "price_doc = train_avg_price['price_doc']\n",
    "Accuracy = []\n",
    "\n",
    "for train_index, test_index in kf.split(train_avg_price):\n",
    "    print(\"TRAIN:\", train_index, \"TEST:\", test_index)\n",
    "    X_train, X_test = train_avg_price.iloc[train_index,:], train_avg_price.iloc[test_index,:]\n",
    "    y_train, y_test = label[train_index], label[test_index]\n",
    "    dtrain = xgb.DMatrix(X_train[col],y_train)\n",
    "    dtest = xgb.DMatrix(X_test[col])\n",
    "    model = xgb.train(params,dtrain,num_boost_round=300)\n",
    "    print('training done')\n",
    "    pred = model.predict(dtest)\n",
    "    #actual_pred = (X_test['Primary Average'] + pred)*X_test['full_sq']\n",
    "    actual_pred = np.exp(model.predict(dtest))-1\n",
    "    RMSLE = mse(np.log1p(price_doc[test_index]),np.log1p(actual_pred))**0.5\n",
    "    print('RMSLE: '+str(RMSLE))\n",
    "    Accuracy.append(RMSLE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  },
  "toc": {
   "nav_menu": {
    "height": "121px",
    "width": "252px"
   },
   "navigate_menu": true,
   "number_sections": true,
   "sideBar": true,
   "threshold": 4,
   "toc_cell": false,
   "toc_section_display": "block",
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
