{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn import model_selection, preprocessing\n",
    "import xgboost as xgb\n",
    "import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train = pd.read_csv('train.csv', parse_dates=['timestamp'])\n",
    "test = pd.read_csv('test.csv', parse_dates=['timestamp'])\n",
    "macro = pd.read_csv('macro.csv', parse_dates=['timestamp'])\n",
    "id_test = test.id"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Clean up Data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#clean data\n",
    "bad_index = train[train.life_sq > train.full_sq].index\n",
    "train.ix[bad_index, \"life_sq\"] = np.NaN\n",
    "equal_index = [601,1896,2791]\n",
    "test.ix[equal_index, \"life_sq\"] = test.ix[equal_index, \"full_sq\"]\n",
    "bad_index = test[test.life_sq > test.full_sq].index\n",
    "test.ix[bad_index, \"life_sq\"] = np.NaN\n",
    "bad_index = train[train.life_sq < 5].index\n",
    "train.ix[bad_index, \"life_sq\"] = np.NaN\n",
    "bad_index = test[test.life_sq < 5].index\n",
    "test.ix[bad_index, \"life_sq\"] = np.NaN\n",
    "bad_index = train[train.full_sq < 5].index\n",
    "train.ix[bad_index, \"full_sq\"] = np.NaN\n",
    "bad_index = test[test.full_sq < 5].index\n",
    "test.ix[bad_index, \"full_sq\"] = np.NaN\n",
    "kitch_is_build_year = [13117]\n",
    "train.ix[kitch_is_build_year, \"build_year\"] = train.ix[kitch_is_build_year, \"kitch_sq\"]\n",
    "bad_index = train[train.kitch_sq >= train.life_sq].index\n",
    "train.ix[bad_index, \"kitch_sq\"] = np.NaN\n",
    "bad_index = test[test.kitch_sq >= test.life_sq].index\n",
    "test.ix[bad_index, \"kitch_sq\"] = np.NaN\n",
    "bad_index = train[(train.kitch_sq == 0).values + (train.kitch_sq == 1).values].index\n",
    "train.ix[bad_index, \"kitch_sq\"] = np.NaN\n",
    "bad_index = test[(test.kitch_sq == 0).values + (test.kitch_sq == 1).values].index\n",
    "test.ix[bad_index, \"kitch_sq\"] = np.NaN\n",
    "bad_index = train[(train.full_sq > 210) & (train.life_sq / train.full_sq < 0.3)].index\n",
    "train.ix[bad_index, \"full_sq\"] = np.NaN\n",
    "bad_index = test[(test.full_sq > 150) & (test.life_sq / test.full_sq < 0.3)].index\n",
    "test.ix[bad_index, \"full_sq\"] = np.NaN\n",
    "bad_index = train[train.life_sq > 300].index\n",
    "train.ix[bad_index, [\"life_sq\", \"full_sq\"]] = np.NaN\n",
    "bad_index = test[test.life_sq > 200].index\n",
    "test.ix[bad_index, [\"life_sq\", \"full_sq\"]] = np.NaN\n",
    "train.product_type.value_counts(normalize= True)\n",
    "test.product_type.value_counts(normalize= True)\n",
    "bad_index = train[train.build_year < 1500].index\n",
    "train.ix[bad_index, \"build_year\"] = np.NaN\n",
    "bad_index = test[test.build_year < 1500].index\n",
    "test.ix[bad_index, \"build_year\"] = np.NaN\n",
    "bad_index = train[train.num_room == 0].index \n",
    "train.ix[bad_index, \"num_room\"] = np.NaN\n",
    "bad_index = test[test.num_room == 0].index \n",
    "test.ix[bad_index, \"num_room\"] = np.NaN\n",
    "bad_index = [10076, 11621, 17764, 19390, 24007, 26713, 29172]\n",
    "train.ix[bad_index, \"num_room\"] = np.NaN\n",
    "bad_index = [3174, 7313]\n",
    "test.ix[bad_index, \"num_room\"] = np.NaN\n",
    "bad_index = train[(train.floor == 0).values * (train.max_floor == 0).values].index\n",
    "train.ix[bad_index, [\"max_floor\", \"floor\"]] = np.NaN\n",
    "bad_index = train[train.floor == 0].index\n",
    "train.ix[bad_index, \"floor\"] = np.NaN\n",
    "bad_index = train[train.max_floor == 0].index\n",
    "train.ix[bad_index, \"max_floor\"] = np.NaN\n",
    "bad_index = test[test.max_floor == 0].index\n",
    "test.ix[bad_index, \"max_floor\"] = np.NaN\n",
    "bad_index = train[train.floor > train.max_floor].index\n",
    "train.ix[bad_index, \"max_floor\"] = np.NaN\n",
    "bad_index = test[test.floor > test.max_floor].index\n",
    "test.ix[bad_index, \"max_floor\"] = np.NaN\n",
    "bad_index = [23584]\n",
    "train.ix[bad_index, \"floor\"] = np.NaN\n",
    "bad_index = train[train.state == 33].index\n",
    "train.ix[bad_index, \"state\"] = np.NaN\n",
    "# brings error down a lot by removing extreme price per sqm\n",
    "train.loc[train.full_sq == 0, 'full_sq'] = 50\n",
    "train = train[train.price_doc/train.full_sq <= 600000]\n",
    "train = train[train.price_doc/train.full_sq >= 10000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y_train = np.log(1+train[\"price_doc\"])\n",
    "col = list(test.columns)[2:]\n",
    "x_train = train[col]\n",
    "x_test = test[col]\n",
    "\n",
    "num_train = len(x_train)\n",
    "x_all = pd.concat([x_train, x_test])\n",
    "cat = []\n",
    "for c in x_all.columns:\n",
    "    if x_all[c].dtype == 'object':\n",
    "        x_all[c] = pd.factorize(x_all[c], sort=True)[0]\n",
    "        cat.append(c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "### Additional Cat Features\n",
    "add_cat = [each for each in list(x_all.columns) if 'ID' in each]\n",
    "add_cat.append('build_year')\n",
    "cat = cat+add_cat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for dd in add_cat:\n",
    "    x_all[dd] = pd.factorize(x_all[dd],sort=True)[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Normalize All con Data in dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import warnings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def normalize(col):\n",
    "    mean = np.nanmean(x_all[col])\n",
    "    std = np.nanstd(x_all[col])\n",
    "    return [(each - mean)/std if np.isnan(each)!=True else np.nan for each in list(x_all[col])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "con_var = [each for each in list(x_all.columns) if each not in cat]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for each in con_var:\n",
    "    x_all[each] = normalize(each)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## Save the data\n",
    "x_train = x_all[:num_train]\n",
    "x_test = x_all[num_train:]\n",
    "#x_train['id'] = train['id']\n",
    "#x_train['timestamp'] = train['timestamp']\n",
    "#x_train['price_doc'] = train['price_doc']\n",
    "#x_test['timestamp'] = test['timestamp']\n",
    "#x_test['id'] = test['id']\n",
    "#x_train.to_csv('train_normalized.csv',index=False)\n",
    "#x_test.to_csv('test_normalized.csv',index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# L2 Model Fitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import Lasso\n",
    "from sklearn.model_selection import cross_val_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def cv_Lasso(lso):\n",
    "    print(lso)\n",
    "    x_train_lasso = x_train.fillna(-999)\n",
    "    cv = cross_val_score(lso,x_train_lasso,y_train,cv=5,scoring='mean_squared_error')\n",
    "    #print(cv)\n",
    "    mean_mse = -1*cv.mean()\n",
    "    print('RMSE: '+str(mean_mse**0.5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lasso(alpha=0.1, copy_X=True, fit_intercept=True, max_iter=1000,\n",
      "   normalize=False, positive=False, precompute=False, random_state=None,\n",
      "   selection='cyclic', tol=0.0001, warm_start=False)\n",
      "RMSE: 0.501600983504\n",
      "Lasso(alpha=0.5, copy_X=True, fit_intercept=True, max_iter=1000,\n",
      "   normalize=False, positive=False, precompute=False, random_state=None,\n",
      "   selection='cyclic', tol=0.0001, warm_start=False)\n",
      "RMSE: 0.576741888574\n",
      "Lasso(alpha=1, copy_X=True, fit_intercept=True, max_iter=1000,\n",
      "   normalize=False, positive=False, precompute=False, random_state=None,\n",
      "   selection='cyclic', tol=0.0001, warm_start=False)\n",
      "RMSE: 0.578438118054\n",
      "Lasso(alpha=5, copy_X=True, fit_intercept=True, max_iter=1000,\n",
      "   normalize=False, positive=False, precompute=False, random_state=None,\n",
      "   selection='cyclic', tol=0.0001, warm_start=False)\n",
      "RMSE: 0.5827268704\n",
      "Lasso(alpha=10, copy_X=True, fit_intercept=True, max_iter=1000,\n",
      "   normalize=False, positive=False, precompute=False, random_state=None,\n",
      "   selection='cyclic', tol=0.0001, warm_start=False)\n",
      "RMSE: 0.586656752231\n",
      "Lasso(alpha=20, copy_X=True, fit_intercept=True, max_iter=1000,\n",
      "   normalize=False, positive=False, precompute=False, random_state=None,\n",
      "   selection='cyclic', tol=0.0001, warm_start=False)\n",
      "RMSE: 0.588917669526\n"
     ]
    }
   ],
   "source": [
    "alpha = [0.1,0.5,1,5,10,20]\n",
    "for aa in alpha:\n",
    "    cv_Lasso(Lasso(alpha=aa))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Lasso(alpha=0.1, copy_X=True, fit_intercept=True, max_iter=1000,\n",
       "   normalize=False, positive=False, precompute=False, random_state=None,\n",
       "   selection='cyclic', tol=0.0001, warm_start=False)"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train_lasso = x_train.fillna(-999)\n",
    "lasso = Lasso(alpha=0.1)\n",
    "lasso.fit(x_train_lasso,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "coeff = lasso.coef_\n",
    "feature = list(x_train_lasso.columns)\n",
    "coeff_tbl= pd.DataFrame({'feature':feature,'coeff':coeff})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "coeff_final = coeff_tbl[coeff_tbl['coeff']!=0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0                                   full_sq\n",
       "1                                   life_sq\n",
       "2                                     floor\n",
       "3                                 max_floor\n",
       "4                                  material\n",
       "5                                build_year\n",
       "6                                  num_room\n",
       "7                                  kitch_sq\n",
       "8                                     state\n",
       "10                                 sub_area\n",
       "16                          preschool_quota\n",
       "22                      hospital_beds_raion\n",
       "66     raion_build_count_with_material_info\n",
       "68                         build_count_wood\n",
       "82                                 ID_metro\n",
       "97                 ID_railroad_station_walk\n",
       "100                ID_railroad_station_avto\n",
       "111                            ID_big_road1\n",
       "114                            ID_big_road2\n",
       "158              cafe_sum_500_min_price_avg\n",
       "159              cafe_sum_500_max_price_avg\n",
       "181             cafe_sum_1000_min_price_avg\n",
       "182             cafe_sum_1000_max_price_avg\n",
       "204             cafe_sum_1500_min_price_avg\n",
       "205             cafe_sum_1500_max_price_avg\n",
       "228             cafe_sum_2000_max_price_avg\n",
       "250             cafe_sum_3000_min_price_avg\n",
       "267                          prom_part_5000\n",
       "273             cafe_sum_5000_min_price_avg\n",
       "Name: feature, dtype: object"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "coeff_final['feature']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Base XGBoost Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\ttrain-rmse:0.483103\ttest-rmse:0.484864\n",
      "[50]\ttrain-rmse:0.462595\ttest-rmse:0.468099\n",
      "[100]\ttrain-rmse:0.46185\ttest-rmse:0.467795\n",
      "[150]\ttrain-rmse:0.461458\ttest-rmse:0.467632\n",
      "[200]\ttrain-rmse:0.461208\ttest-rmse:0.467539\n",
      "[250]\ttrain-rmse:0.461041\ttest-rmse:0.4675\n",
      "281\n"
     ]
    }
   ],
   "source": [
    "xgb_params = {\n",
    "    #'booster':'gblinear',\n",
    "    'eta': 0.05,\n",
    "    'max_depth': 5,\n",
    "    'subsample': 0.7,\n",
    "    'colsample_bytree': 0.7,\n",
    "    'objective': 'reg:linear',\n",
    "    'eval_metric': 'rmse',\n",
    "    'silent': 1\n",
    "}\n",
    "\n",
    "dtrain = xgb.DMatrix(x_train, y_train)\n",
    "dtest = xgb.DMatrix(x_test)\n",
    "cv_output = xgb.cv(xgb_params, dtrain, num_boost_round=4000, early_stopping_rounds=20,\n",
    "    verbose_eval=50, show_stdv=False)\n",
    "print(len(cv_output))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## With Linear Booster eta 5 tree 8\n",
    "#[2850]\ttrain-rmse:0.460279\ttest-rmse:0.467247\n",
    "#[2900]\ttrain-rmse:0.460273\ttest-rmse:0.467245\n",
    "#2927\n",
    "## With Lambda as 5\n",
    "#[0]\ttrain-rmse:14.3692\ttest-rmse:14.3692\n",
    "#[50]\ttrain-rmse:1.20731\ttest-rmse:1.21133\n",
    "#[100]\ttrain-rmse:0.442692\ttest-rmse:0.467986\n",
    "#[150]\ttrain-rmse:0.417063\ttest-rmse:0.455566\n",
    "#[200]\ttrain-rmse:0.403856\ttest-rmse:0.454054\n",
    "#[250]\ttrain-rmse:0.392721\ttest-rmse:0.453433\n",
    "#Base Model\n",
    "#[0]\ttrain-rmse:14.3689\ttest-rmse:14.3689\n",
    "#[50]\ttrain-rmse:1.19822\ttest-rmse:1.20359\n",
    "#[100]\ttrain-rmse:0.435903\ttest-rmse:0.466432\n",
    "#[150]\ttrain-rmse:0.410839\ttest-rmse:0.455221\n",
    "#[200]\ttrain-rmse:0.397977\ttest-rmse:0.45433\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model = xgb.train(xgb_params,dtrain,num_boost_round=len(cv_output))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_feature_importance(model):\n",
    "    Importance = model.get_fscore()\n",
    "    Importance = list(Importance.items())\n",
    "    Feature= []\n",
    "    Score = []\n",
    "    for each in Importance:\n",
    "        Feature.append(each[0])\n",
    "        Score.append(each[1])\n",
    "    df = pd.DataFrame({'Feature':Feature,'Score':Score}).sort_values(by=['Score'],ascending=[0])\n",
    "    return df    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "feature_importance_puremodel = get_feature_importance(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pred_puremodel = np.exp(model.predict(dtest))-1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
