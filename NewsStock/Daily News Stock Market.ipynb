{
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0,
 "cells": [
  {
   "cell_type": "markdown",
   "source": "# A pipeline for predictive analytics using text data",
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": "## Before we start",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": "import numpy as np \nimport pandas as pd \nimport sklearn\nimport matplotlib.pyplot as plt\n%matplotlib inline\nfrom sklearn.cross_validation import train_test_split\nfrom wordcloud import WordCloud,STOPWORDS\nimport re\nimport nltk\nfrom nltk.corpus import stopwords\ndf = pd.read_csv('../input/Combined_News_DJIA.csv')\nprint(df.shape)\nimport matplotlib\nmatplotlib.rcParams[\"figure.figsize\"] = \"8, 8\"",
   "execution_count": null,
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": "df.head(5)",
   "execution_count": null,
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": "Credits to **Kate**, for the great method of combining all headlines.",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": "df['Combined']=df.iloc[:,2:27].apply(lambda row: ''.join(str(row.values)), axis=1)",
   "execution_count": null,
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": "train,test = train_test_split(df,test_size=0.2,random_state=42)",
   "execution_count": null,
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": "## Simple EDA",
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": "We first have a quick look at the text, looking for words that can be the indicator of decrease on stock price.",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": "non_decrease = train[train['Label']==1]\ndecrease = train[train['Label']==0]\nprint(len(non_decrease)/len(df))",
   "execution_count": null,
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": "We can see that the occurrence of non-decrease situation is almost the **same** as that of a decrease market. ",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": "def to_words(content):\n    letters_only = re.sub(\"[^a-zA-Z]\", \" \", content) \n    words = letters_only.lower().split()                             \n    stops = set(stopwords.words(\"english\"))                  \n    meaningful_words = [w for w in words if not w in stops] \n    return( \" \".join( meaningful_words )) ",
   "execution_count": null,
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": "non_decrease_word=[]\ndecrease_word=[]\nfor each in non_decrease['Combined']:\n    non_decrease_word.append(to_words(each))\n\nfor each in decrease['Combined']:\n    decrease_word.append(to_words(each))",
   "execution_count": null,
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": "wordcloud1 = WordCloud(background_color='black',\n                      width=3000,\n                      height=2500\n                     ).generate(decrease_word[0])",
   "execution_count": null,
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": "plt.figure(1,figsize=(8,8))\nplt.imshow(wordcloud1)\nplt.axis('off')\nplt.show()",
   "execution_count": null,
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": "wordcloud2 = WordCloud(background_color='white',\n                      width=3000,\n                      height=2500\n                     ).generate(non_decrease_word[0])",
   "execution_count": null,
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": "plt.figure(1,figsize=(8,8))\nplt.imshow(wordcloud2)\nplt.axis('off')\nplt.show()",
   "execution_count": null,
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": "If you look at two word clouds, you may find that even in the case of non-decreased situation the **Political sensitive words** are dominant.  Therefore, I have a feeling that the overall results of the classification may not be quite good since the features of two classes are **not that distinct**.",
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": "## Feature extraction",
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": "I choose to use **tf-idf** model for feature extraction as it can make the informative features weighted enough.",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": "from sklearn.feature_extraction.text import TfidfVectorizer\ntfidf=TfidfVectorizer()\ntrain_text = []\ntest_text = []\nfor each in train['Combined']:\n    train_text.append(to_words(each))\n\nfor each in test['Combined']:\n    test_text.append(to_words(each))\ntrain_features = tfidf.fit_transform(train_text)\ntest_features = tfidf.transform(test_text)",
   "execution_count": null,
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": "## Model fitting",
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": "`In this part, I will fit seven different classifiers on the training set. ",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": "from sklearn.linear_model import LogisticRegression\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.svm import SVC\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier, GradientBoostingClassifier\nfrom sklearn.naive_bayes import GaussianNB\nfrom sklearn.metrics import accuracy_score\nfrom sklearn.metrics import roc_curve\nfrom ggplot import *",
   "execution_count": null,
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": "Classifiers = [\n    LogisticRegression(C=0.000000001,solver='liblinear',max_iter=200),\n    KNeighborsClassifier(3),\n    SVC(kernel=\"rbf\", C=0.025, probability=True),\n    DecisionTreeClassifier(),\n    RandomForestClassifier(n_estimators=200),\n    AdaBoostClassifier(),\n    GaussianNB()]",
   "execution_count": null,
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": "dense_features=train_features.toarray()\ndense_test= test_features.toarray()\nAccuracy=[]\nModel=[]\nfor classifier in Classifiers:\n    try:\n        fit = classifier.fit(train_features,train['Label'])\n        pred = fit.predict(test_features)\n        prob = fit.predict_proba(test_features)[:,1]\n    except Exception:\n        fit = classifier.fit(dense_features,train['Label'])\n        pred = fit.predict(dense_test)\n        prob = fit.predict_proba(dense_test)[:,1]\n    accuracy = accuracy_score(pred,test['Label'])\n    Accuracy.append(accuracy)\n    Model.append(classifier.__class__.__name__)\n    print('Accuracy of '+classifier.__class__.__name__+' is '+str(accuracy))\n    fpr, tpr, _ = roc_curve(test['Label'],prob)\n    tmp = pd.DataFrame(dict(fpr=fpr, tpr=tpr))\n    g = ggplot(tmp, aes(x='fpr', y='tpr')) +geom_line() +geom_abline(linetype='dashed')+ ggtitle('Roc Curve of '+classifier.__class__.__name__)\n    print(g)",
   "execution_count": null,
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": "## Conclusion",
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": "Obviously, the overall performances of seven models are not quite good. The features are not distinct enough, therefore resulting in a bad model fitting.",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": "",
   "execution_count": null,
   "outputs": [],
   "metadata": {}
  }
 ]
}